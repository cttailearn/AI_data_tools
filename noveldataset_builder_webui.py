# -*- coding: utf-8 -*-
"""
å°è¯´æ•°æ®é›†æ„å»º WebUIï¼ˆJSONL messages æ ¼å¼ï¼‰
- æ”¯æŒä¸Šä¼ TXTæ–‡ä»¶æˆ–æŒ‡å®šç›®å½•
- æ™ºèƒ½åˆ†æ®µï¼ŒæŒ‰æ®µè½åˆå¹¶è‡³é˜ˆå€¼
- åŠ©æ‰‹å†…å®¹å¯é€‰æ‹©ï¼šAIç”Ÿæˆ / ä½¿ç”¨åŸæ–‡ / ç•™ç©º
- å¯é…ç½® system æç¤ºè¯ä¸ä»»åŠ¡ç±»å‹ï¼ˆå†™ä½œ/ç»­å†™/ä¿®æ”¹ï¼‰
- å†…ç½®æ¨¡å‹è¿æ¥å’Œæç¤ºè¯ä»»åŠ¡ç®¡ç†ï¼Œç‹¬ç«‹è¿è¡Œ
"""
import os, re, sys, json, time, logging
from pathlib import Path
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass
from urllib.parse import urlparse
import gradio as gr
import openai
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

# å°è¯•å¯¼å…¥ chardetï¼ˆå¯é€‰ï¼‰
try:
    import chardet
    HAS_CHARDET = True
except Exception:
    HAS_CHARDET = False

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ==================== AIæ¨¡å‹é…ç½®å’Œå®¢æˆ·ç«¯ ====================

@dataclass
class ModelConfig:
    """AIæ¨¡å‹é…ç½®ç±»"""
    name: str
    base_url: str
    api_key: str
    model_name: str
    timeout: int = 30
    max_retries: int = 3
    temperature: float = 0.7
    max_tokens: Optional[int] = 2048
    
    def __post_init__(self):
        """é…ç½®éªŒè¯"""
        if not self.base_url or not self.api_key or not self.model_name:
            raise ValueError("base_url, api_key, model_name ä¸èƒ½ä¸ºç©º")
        
        # éªŒè¯URLæ ¼å¼
        parsed = urlparse(self.base_url)
        if not parsed.scheme or not parsed.netloc:
            raise ValueError("base_url æ ¼å¼æ— æ•ˆ")

class AIModelClient:
    """AIæ¨¡å‹å®¢æˆ·ç«¯"""
    
    @classmethod
    def get_preset_configs(cls) -> Dict[str, Dict]:
        """è·å–é¢„è®¾æ¨¡å‹é…ç½®"""
        return {
            "DeepSeek": {
                "name": "DeepSeek",
                "base_url": "https://api.deepseek.com/v1",
                "api_key": "",
                "model_name": "deepseek-chat",
                "timeout": 30,
                "temperature": 0.7
            },
            "OpenAI": {
                "name": "OpenAI",
                "base_url": "https://api.openai.com/v1",
                "api_key": "",
                "model_name": "gpt-4o-mini",
                "timeout": 30,
                "temperature": 0.7
            },
            "æœ¬åœ°æ¨¡å‹": {
                "name": "æœ¬åœ°æ¨¡å‹",
                "base_url": "http://localhost:11434/v1",
                "api_key": "ollama",
                "model_name": "qwen2.5:7b",
                "timeout": 60,
                "temperature": 0.7
            }
        }
    
    @classmethod
    def load_custom_configs(cls) -> Dict[str, Dict]:
        """åŠ è½½è‡ªå®šä¹‰æ¨¡å‹é…ç½®"""
        config_file = "model_configs.json"
        try:
            if os.path.exists(config_file):
                with open(config_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except Exception as e:
            logger.warning(f"åŠ è½½æ¨¡å‹é…ç½®å¤±è´¥: {str(e)}")
        return {}
    
    @classmethod
    def save_custom_config(cls, config: Dict):
        """ä¿å­˜è‡ªå®šä¹‰æ¨¡å‹é…ç½®"""
        config_file = "model_configs.json"
        try:
            existing = cls.load_custom_configs()
            existing[config['name']] = config
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(existing, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜æ¨¡å‹é…ç½®å¤±è´¥: {str(e)}")
    
    @classmethod
    def get_all_configs(cls) -> Dict[str, Dict]:
        """è·å–æ‰€æœ‰é…ç½®ï¼ˆé¢„è®¾+è‡ªå®šä¹‰ï¼‰"""
        configs = cls.get_preset_configs()
        configs.update(cls.load_custom_configs())
        return configs
    
    def __init__(self, config: ModelConfig):
        self.config = config
        self.client = openai.OpenAI(
            base_url=config.base_url,
            api_key=config.api_key,
            timeout=config.timeout,
            max_retries=config.max_retries
        )
        logger.info(f"AIæ¨¡å‹å®¢æˆ·ç«¯å·²åˆå§‹åŒ–: {config.name}")
    
    @retry(
        stop=stop_after_attempt(5),
        wait=wait_exponential(multiplier=1, min=4, max=10),
        retry=retry_if_exception_type((
            openai.RateLimitError, 
            openai.APITimeoutError,
            openai.APIConnectionError,
            ConnectionError,
            TimeoutError,
            Exception
        ))
    )
    def process_text(self, text: str, prompt: str) -> str:
        """ä½¿ç”¨AIæ¨¡å‹å¤„ç†æ–‡æœ¬"""
        start_time = time.time()
        
        try:
            # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œè¿‡é•¿çš„æ–‡æœ¬è¿›è¡Œæˆªæ–­
            if len(text) > 8000:
                text = text[:8000] + "...[æ–‡æœ¬è¿‡é•¿å·²æˆªæ–­]"
                logger.warning(f"è¾“å…¥æ–‡æœ¬è¿‡é•¿ï¼Œå·²æˆªæ–­è‡³8000å­—ç¬¦")
            
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬å¤„ç†åŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚å¤„ç†æ–‡æœ¬å†…å®¹ã€‚è¯·ä¿æŒå›å¤ç®€æ´æ˜äº†ã€‚"},
                {"role": "user", "content": f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚å¤„ç†æ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{prompt}\n\næ–‡æœ¬å†…å®¹ï¼š{text}"}
            ]
            
            # è®¾ç½®åˆç†çš„max_tokensé™åˆ¶
            max_tokens = self.config.max_tokens
            if max_tokens is None or max_tokens > 4096:
                estimated_tokens = min(len(text), 2048)
                max_tokens = max(estimated_tokens, 256)
            
            max_tokens = min(max_tokens, 2048)
            
            response = self.client.chat.completions.create(
                model=self.config.model_name,
                messages=messages,
                temperature=self.config.temperature,
                max_tokens=max_tokens,
                stop=["<|im_end|>", "<|endoftext|>", "\n\n\n", "<|im_start|>", "\n\n"],
                timeout=self.config.timeout
            )
            
            result = response.choices[0].message.content.strip()
            
            # è®°å½•å¤„ç†æ—¶é—´
            elapsed_time = time.time() - start_time
            if elapsed_time > 20:
                logger.warning(f"æ–‡æœ¬å¤„ç†è€—æ—¶è¾ƒé•¿: {elapsed_time:.2f}ç§’")
            
            return result
            
        except (openai.APIConnectionError, ConnectionError) as e:
            logger.warning(f"è¿æ¥é”™è¯¯ï¼Œæ­£åœ¨é‡è¯•: {str(e)}")
            raise
        except (openai.APITimeoutError, TimeoutError) as e:
            logger.warning(f"è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•: {str(e)}")
            raise
        except openai.RateLimitError as e:
            logger.warning(f"è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼Œæ­£åœ¨é‡è¯•: {str(e)}")
            raise
        except Exception as e:
            logger.error(f"AIå¤„ç†å¤±è´¥: {str(e)}ï¼Œæ­£åœ¨é‡è¯•")
            raise
    
    def test_connection(self) -> bool:
        """æµ‹è¯•è¿æ¥"""
        try:
            response = self.process_text("æµ‹è¯•", "è¯·å›å¤'è¿æ¥æˆåŠŸ'")
            return "è¿æ¥æˆåŠŸ" in response or "æˆåŠŸ" in response
        except Exception:
            return False

# ==================== æç¤ºè¯ä»»åŠ¡ç®¡ç† ====================

class PromptTaskManager:
    """æç¤ºè¯ä»»åŠ¡ç®¡ç†å™¨"""
    
    def __init__(self):
        self.tasks_file = "prompt_tasks.json"
        self.custom_tasks_file = "custom_tasks.json"
        self._load_tasks()
    
    def _load_tasks(self):
        """åŠ è½½ä»»åŠ¡"""
        # é¢„è®¾ä»»åŠ¡
        self.predefined_tasks = {
            "å°è¯´ç»­å†™": "è¯·æ ¹æ®ä¸Šæ–‡å†…å®¹ï¼Œè‡ªç„¶åœ°ç»­å†™æ¥ä¸‹æ¥çš„æƒ…èŠ‚ã€‚ä¿æŒåŸæœ‰çš„å†™ä½œé£æ ¼ã€äººç‰©æ€§æ ¼å’Œæ•…äº‹èŠ‚å¥ã€‚ç»­å†™å†…å®¹åº”è¯¥åœ¨300-500å­—ä¹‹é—´ï¼Œæƒ…èŠ‚è¦æœ‰é€»è¾‘æ€§å’Œè¿è´¯æ€§ã€‚",
            "æ–‡æœ¬æ¶¦è‰²": "è¯·å¯¹ä»¥ä¸‹æ–‡æœ¬è¿›è¡Œæ¶¦è‰²å’Œä¼˜åŒ–ï¼Œæå‡è¯­è¨€è¡¨è¾¾çš„æµç•…æ€§ã€å‡†ç¡®æ€§å’Œæ–‡å­¦æ€§ã€‚ä¿æŒåŸæ„ä¸å˜ï¼Œä½†è®©è¡¨è¾¾æ›´åŠ ç”ŸåŠ¨ã€è‡ªç„¶ã€‚",
            "å¯¹è¯ä¼˜åŒ–": "è¯·ä¼˜åŒ–ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œä½¿å…¶æ›´åŠ è‡ªç„¶ã€ç”ŸåŠ¨ï¼Œç¬¦åˆäººç‰©æ€§æ ¼ç‰¹ç‚¹ã€‚æ³¨æ„å¯¹è¯çš„èŠ‚å¥æ„Ÿå’ŒçœŸå®æ„Ÿã€‚",
            "åœºæ™¯æå†™": "è¯·æ ¹æ®ç»™å®šçš„åœºæ™¯è¦ç´ ï¼Œåˆ›ä½œä¸€æ®µç”ŸåŠ¨çš„åœºæ™¯æå†™ã€‚æ³¨é‡ç»†èŠ‚åˆ»ç”»ï¼Œè¥é€ æ°›å›´æ„Ÿï¼Œå­—æ•°æ§åˆ¶åœ¨200-400å­—ã€‚",
            "äººç‰©åˆ»ç”»": "è¯·æ ¹æ®ç»™å®šçš„äººç‰©ä¿¡æ¯ï¼Œåˆ›ä½œä¸€æ®µäººç‰©æå†™ã€‚çªå‡ºäººç‰©çš„å¤–è²Œç‰¹å¾ã€æ€§æ ¼ç‰¹ç‚¹æˆ–å¿ƒç†çŠ¶æ€ï¼Œå­—æ•°æ§åˆ¶åœ¨200-300å­—ã€‚",
            "æƒ…èŠ‚æ„æ€": "è¯·æ ¹æ®ç»™å®šçš„æ•…äº‹èƒŒæ™¯å’Œè¦æ±‚ï¼Œæ„æ€ä¸€ä¸ªå®Œæ•´çš„æƒ…èŠ‚å‘å±•ã€‚åŒ…æ‹¬èµ·å› ã€ç»è¿‡ã€é«˜æ½®å’Œç»“å±€ï¼Œé€»è¾‘æ¸…æ™°ï¼Œæƒ…èŠ‚ç´§å‡‘ã€‚"
        }
        
        # åŠ è½½è‡ªå®šä¹‰ä»»åŠ¡
        self.custom_tasks = {}
        try:
            if os.path.exists(self.custom_tasks_file):
                with open(self.custom_tasks_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # ç¡®ä¿åŠ è½½çš„æ•°æ®æ˜¯å­—å…¸æ ¼å¼
                    if isinstance(data, dict):
                        self.custom_tasks = data
                    else:
                        logger.warning(f"è‡ªå®šä¹‰ä»»åŠ¡æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œå·²é‡ç½®ä¸ºç©ºå­—å…¸")
                        self.custom_tasks = {}
        except Exception as e:
            logger.warning(f"åŠ è½½è‡ªå®šä¹‰ä»»åŠ¡å¤±è´¥: {str(e)}")
            self.custom_tasks = {}
    
    def get_all_tasks(self) -> Dict[str, str]:
        """è·å–æ‰€æœ‰ä»»åŠ¡"""
        all_tasks = self.predefined_tasks.copy()
        all_tasks.update(self.custom_tasks)
        return all_tasks
    
    def get_task_names(self) -> List[str]:
        """è·å–ä»»åŠ¡åç§°åˆ—è¡¨"""
        return list(self.get_all_tasks().keys())
    
    def get_task_prompt(self, task_name: str) -> str:
        """è·å–ä»»åŠ¡æç¤ºè¯"""
        all_tasks = self.get_all_tasks()
        return all_tasks.get(task_name, "")
    
    def add_custom_task(self, name: str, prompt: str) -> bool:
        """æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡"""
        try:
            self.custom_tasks[name] = prompt
            with open(self.custom_tasks_file, 'w', encoding='utf-8') as f:
                json.dump(self.custom_tasks, f, ensure_ascii=False, indent=2)
            return True
        except Exception as e:
            logger.error(f"æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False
    
    def delete_custom_task(self, name: str) -> bool:
        """åˆ é™¤è‡ªå®šä¹‰ä»»åŠ¡"""
        try:
            if name in self.custom_tasks:
                del self.custom_tasks[name]
                with open(self.custom_tasks_file, 'w', encoding='utf-8') as f:
                    json.dump(self.custom_tasks, f, ensure_ascii=False, indent=2)
                return True
            return False
        except Exception as e:
            logger.error(f"åˆ é™¤è‡ªå®šä¹‰ä»»åŠ¡å¤±è´¥: {str(e)}")
            return False

# ==================== å…¨å±€å˜é‡ ====================

# å…¨å±€å˜é‡
current_model_client = None
task_manager = PromptTaskManager()

# ==================== åŸºæœ¬å·¥å…·å‡½æ•° ====================

def detect_encoding(file_path: str) -> str:
    if HAS_CHARDET:
        try:
            with open(file_path, 'rb') as f:
                raw = f.read(10000)
            r = chardet.detect(raw)
            if r.get('encoding') and r.get('confidence', 0) > 0.7:
                return r['encoding']
        except Exception:
            pass
    for enc in ['utf-8', 'utf-8-sig', 'gbk', 'gb2312', 'gb18030', 'big5', 'latin1']:
        try:
            with open(file_path, 'r', encoding=enc) as f:
                f.read(1000)
            return enc
        except Exception:
            continue
    return 'utf-8'

def read_text(file_path: str) -> str:
    enc = detect_encoding(file_path)
    with open(file_path, 'r', encoding=enc, errors='ignore') as f:
        return f.read()

# ç®€æ˜“åˆ†æ®µï¼šæŒ‰åŒæ¢è¡Œåˆ†æ®µï¼Œåˆå¹¶è‡³ [min_len, max_len]

def split_text(text: str, min_len: int = 200, max_len: int = 800) -> List[str]:
    paras = [p.strip() for p in re.split(r"\n{2,}", text) if p.strip()]
    segs, cur = [], ''
    for p in paras:
        if not cur:
            cur = p
        elif len(cur) + len(p) + 2 <= max_len:
            cur += "\n\n" + p
        else:
            if len(cur) < min_len and segs:
                segs[-1] += "\n\n" + cur
            else:
                segs.append(cur)
            cur = p
    if cur:
        if len(cur) < min_len and segs:
            segs[-1] += "\n\n" + cur
        else:
            segs.append(cur)
    return segs

# æ„å»º messagesï¼ˆä¿ç•™å…¼å®¹å‡½æ•°ï¼‰

def build_messages(segment: str, system_prompt: str, task_type: str, user_extra: str) -> List[Dict[str, str]]:
    """æ„å»ºmessagesï¼ˆå…¼å®¹å‡½æ•°ï¼Œæ–°ç‰ˆæœ¬ä¸­å·²åœ¨build_jsonlä¸­ç›´æ¥æ„å»ºï¼‰"""
    if task_type == 'ç»­å†™':
        user_msg = f"è¯·ç»­å†™ä»¥ä¸‹æ®µè½ï¼š\n\nã€{segment}ã€"
    elif task_type == 'ä¿®æ”¹':
        hint = user_extra.strip() or 'è¯·ä¼˜åŒ–æ–‡ç¬”ï¼Œä½¿å…¶æ›´æµç•…ã€ç”ŸåŠ¨ä¸”ç¬¦åˆä¸­æ–‡å†™ä½œä¹ æƒ¯ã€‚'
        user_msg = f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–è¿™æ®µæ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{hint}\n\næ–‡æœ¬ï¼š\nã€{segment}ã€"
    else:  # å†™ä½œ
        prompt = user_extra.strip() or 'è¯·æ ¹æ®ç»™å®šé¢˜æä¸é£æ ¼åˆ›ä½œä¸€æ®µå°è¯´ç‰‡æ®µï¼ˆ300-500å­—ï¼‰ã€‚'
        user_msg = prompt
    return [
        {"role": "system", "content": system_prompt.strip() or "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ã€‚"},
        {"role": "user", "content": user_msg}
    ]

# AI ç”ŸæˆåŠ©æ‰‹å›å¤

def ai_generate_continuation(client: AIModelClient, segment: str, user_extra: str, selected_task: str = "") -> str:
    """ç”Ÿæˆç»­å†™å†…å®¹"""
    # æ ¹æ®é€‰æ‹©çš„ä»»åŠ¡æ¨¡æ¿æ„å»ºæç¤ºè¯
    if selected_task and selected_task != "è‡ªå®šä¹‰":
        prompt = task_manager.get_task_prompt(selected_task)
        if not prompt:
            prompt = 'è¯·æ ¹æ®ä¸Šæ–‡å†…å®¹ï¼Œè‡ªç„¶åœ°ç»­å†™æ¥ä¸‹æ¥çš„æƒ…èŠ‚ã€‚ä¿æŒåŸæœ‰çš„å†™ä½œé£æ ¼ã€äººç‰©æ€§æ ¼å’Œæ•…äº‹èŠ‚å¥ã€‚ç»­å†™å†…å®¹åº”è¯¥åœ¨300-500å­—ä¹‹é—´ï¼Œæƒ…èŠ‚è¦æœ‰é€»è¾‘æ€§å’Œè¿è´¯æ€§ã€‚'
    else:
        prompt = 'è¯·æ ¹æ®ä¸Šæ–‡å†…å®¹ï¼Œè‡ªç„¶åœ°ç»­å†™æ¥ä¸‹æ¥çš„æƒ…èŠ‚ã€‚ä¿æŒåŸæœ‰çš„å†™ä½œé£æ ¼ã€äººç‰©æ€§æ ¼å’Œæ•…äº‹èŠ‚å¥ã€‚ç»­å†™å†…å®¹åº”è¯¥åœ¨300-500å­—ä¹‹é—´ï¼Œæƒ…èŠ‚è¦æœ‰é€»è¾‘æ€§å’Œè¿è´¯æ€§ã€‚'
    
    text = segment
    if user_extra.strip():
        text += f"\n\nç»­å†™è¦æ±‚ï¼š{user_extra.strip()}"
    
    try:
        result = client.process_text(text, prompt)
        if not result or result.strip() == "":
            return f"[AIç”Ÿæˆå†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–é‡è¯•]"
        return result.strip()
    except Exception as e:
        logger.error(f"AIç»­å†™ç”Ÿæˆå¤±è´¥: {str(e)}")
        return f"[AIç»­å†™ç”Ÿæˆå¤±è´¥: {str(e)}]"

def ai_generate_writing(client: AIModelClient, segment: str, user_extra: str, selected_task: str = "") -> str:
    """ç”Ÿæˆå†™ä½œå†…å®¹"""
    # æ ¹æ®é€‰æ‹©çš„ä»»åŠ¡æ¨¡æ¿æ„å»ºæç¤ºè¯
    if selected_task and selected_task != "è‡ªå®šä¹‰":
        prompt = task_manager.get_task_prompt(selected_task)
        if not prompt:
            prompt = 'è¯·æ ¹æ®å‚è€ƒæ–‡æœ¬å’Œåˆ›ä½œè¦æ±‚ï¼Œç”Ÿæˆä¸€æ®µé«˜è´¨é‡çš„å°è¯´å†…å®¹ã€‚ä¿æŒæ–‡é£ä¸€è‡´ï¼Œæƒ…èŠ‚åˆç†ï¼Œå­—æ•°æ§åˆ¶åœ¨300-500å­—ã€‚'
    else:
        prompt = 'è¯·æ ¹æ®å‚è€ƒæ–‡æœ¬å’Œåˆ›ä½œè¦æ±‚ï¼Œç”Ÿæˆä¸€æ®µé«˜è´¨é‡çš„å°è¯´å†…å®¹ã€‚ä¿æŒæ–‡é£ä¸€è‡´ï¼Œæƒ…èŠ‚åˆç†ï¼Œå­—æ•°æ§åˆ¶åœ¨300-500å­—ã€‚'
    
    requirements = user_extra.strip() or 'è¯·æ ¹æ®ä»¥ä¸‹æ–‡æœ¬å†…å®¹ï¼Œåˆ›ä½œç›¸å…³çš„å°è¯´ç‰‡æ®µã€‚'
    text = f"å‚è€ƒæ–‡æœ¬ï¼š{segment}\n\nåˆ›ä½œè¦æ±‚ï¼š{requirements}"
    
    try:
        result = client.process_text(text, prompt)
        if not result or result.strip() == "":
            return f"[AIç”Ÿæˆå†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–é‡è¯•]"
        return result.strip()
    except Exception as e:
        logger.error(f"AIå†™ä½œç”Ÿæˆå¤±è´¥: {str(e)}")
        return f"[AIå†™ä½œç”Ÿæˆå¤±è´¥: {str(e)}]"

def ai_generate_modification(client: AIModelClient, segment: str, user_extra: str, selected_task: str = "") -> str:
    """ç”Ÿæˆä¿®æ”¹åçš„å†…å®¹"""
    # æ ¹æ®é€‰æ‹©çš„ä»»åŠ¡æ¨¡æ¿æ„å»ºæç¤ºè¯
    if selected_task and selected_task != "è‡ªå®šä¹‰":
        prompt = task_manager.get_task_prompt(selected_task)
        if not prompt:
            prompt = 'è¯·å¯¹åŸæ–‡è¿›è¡Œæ¶¦è‰²å’Œä¼˜åŒ–ï¼Œæå‡è¯­è¨€è¡¨è¾¾çš„æµç•…æ€§ã€å‡†ç¡®æ€§å’Œæ–‡å­¦æ€§ã€‚ä¿æŒåŸæ„ä¸å˜ï¼Œä½†è®©è¡¨è¾¾æ›´åŠ ç”ŸåŠ¨ã€è‡ªç„¶ã€‚'
    else:
        prompt = 'è¯·å¯¹åŸæ–‡è¿›è¡Œæ¶¦è‰²å’Œä¼˜åŒ–ï¼Œæå‡è¯­è¨€è¡¨è¾¾çš„æµç•…æ€§ã€å‡†ç¡®æ€§å’Œæ–‡å­¦æ€§ã€‚ä¿æŒåŸæ„ä¸å˜ï¼Œä½†è®©è¡¨è¾¾æ›´åŠ ç”ŸåŠ¨ã€è‡ªç„¶ã€‚'
    
    need = user_extra.strip() or 'æå‡æ–‡ç¬”ä¸å¯è¯»æ€§ï¼Œä¿æŒåŸæ„ä¸å˜ï¼Œä¼˜åŒ–è¡¨è¾¾æ–¹å¼ã€‚'
    text = f"åŸæ–‡ï¼š{segment}\n\nä¿®æ”¹è¦æ±‚ï¼š{need}"
    
    try:
        result = client.process_text(text, prompt)
        if not result or result.strip() == "":
            return f"[AIç”Ÿæˆå†…å®¹ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–é‡è¯•]"
        return result.strip()
    except Exception as e:
        logger.error(f"AIä¿®æ”¹ç”Ÿæˆå¤±è´¥: {str(e)}")
        return f"[AIä¿®æ”¹ç”Ÿæˆå¤±è´¥: {str(e)}]"

def ai_generate_writing_prompt(client: AIModelClient, assistant_content: str, user_extra: str) -> str:
    """æ ¹æ®ç”Ÿæˆçš„å†…å®¹åæ¨åˆ›ä½œè¦æ±‚"""
    try:
        prompt = "è¯·æ ¹æ®ä»¥ä¸‹ç”Ÿæˆçš„å°è¯´å†…å®¹ï¼Œåæ¨å‡ºä¸€ä¸ªåˆç†çš„åˆ›ä½œè¦æ±‚æˆ–å†™ä½œæŒ‡ä»¤ï¼Œä½œä¸ºç”¨æˆ·çš„æé—®ã€‚è¦æ±‚ç®€æ´æ˜äº†ï¼Œç¬¦åˆåˆ›ä½œé€»è¾‘ã€‚æ ¼å¼å¦‚ï¼š'å†™ä¸€ä¸ª[é¢˜æ]å°è¯´çš„[åœºæ™¯]ï¼Œ[å…·ä½“è¦æ±‚]ã€‚'"
        text = f"ç”Ÿæˆçš„å†…å®¹ï¼š{assistant_content}\n\nç”¨æˆ·é¢å¤–è¦æ±‚ï¼š{user_extra}"
        
        result = client.process_text(text, prompt)
        if not result or result.strip() == "":
            return user_extra.strip() or "è¯·åˆ›ä½œä¸€æ®µå°è¯´å†…å®¹ã€‚"
        return result.strip()
    except Exception as e:
        logger.error(f"ç”Ÿæˆå†™ä½œæç¤ºè¯å¤±è´¥: {str(e)}")
        return user_extra.strip() or "è¯·åˆ›ä½œä¸€æ®µå°è¯´å†…å®¹ã€‚"

def ai_generate_modification_prompt(client: AIModelClient, original_segment: str, modified_content: str, user_extra: str) -> Tuple[str, str]:
    """æ ¹æ®ä¿®æ”¹åçš„å†…å®¹åæ¨åŸæ–‡å’Œä¿®æ”¹è¦æ±‚"""
    try:
        # ç”Ÿæˆä¿®æ”¹è¦æ±‚
        prompt = "è¯·æ ¹æ®åŸæ–‡å’Œä¿®æ”¹åçš„å†…å®¹ï¼Œæ¨æ–­å‡ºç”¨æˆ·å¯èƒ½æå‡ºçš„ä¿®æ”¹è¦æ±‚ã€‚è¦æ±‚ç®€æ´æ˜äº†ï¼Œå…·ä½“å¯æ“ä½œã€‚"
        text = f"åŸæ–‡ï¼š{original_segment}\n\nä¿®æ”¹åå†…å®¹ï¼š{modified_content}\n\nç”¨æˆ·é¢å¤–è¦æ±‚ï¼š{user_extra}"
        
        modification_request = client.process_text(text, prompt)
        if not modification_request or modification_request.strip() == "":
            modification_request = user_extra.strip() or "è¯·ä¼˜åŒ–æ–‡ç¬”ï¼Œä½¿å…¶æ›´æµç•…ã€ç”ŸåŠ¨ä¸”ç¬¦åˆä¸­æ–‡å†™ä½œä¹ æƒ¯ã€‚"
        
        # ç”Ÿæˆç¨å¾®ç®€åŒ–çš„åŸæ–‡ï¼ˆæ¨¡æ‹Ÿæœªä¿®æ”¹å‰çš„çŠ¶æ€ï¼‰
        prompt2 = "è¯·å°†ä»¥ä¸‹æ–‡æœ¬ç¨å¾®ç®€åŒ–ï¼Œé™ä½æ–‡å­¦æ€§ï¼Œæ¨¡æ‹Ÿä¿®æ”¹å‰çš„åŸå§‹çŠ¶æ€ã€‚ä¿æŒä¸»è¦å†…å®¹ä¸å˜ï¼Œä½†è¡¨è¾¾æ›´æœ´ç´ ä¸€äº›ã€‚"
        original_text = client.process_text(modified_content, prompt2)
        if not original_text or original_text.strip() == "":
            original_text = original_segment
        
        return original_text.strip(), modification_request.strip()
    except Exception as e:
        logger.error(f"ç”Ÿæˆä¿®æ”¹æç¤ºè¯å¤±è´¥: {str(e)}")
        modification_request = user_extra.strip() or "è¯·ä¼˜åŒ–æ–‡ç¬”ï¼Œä½¿å…¶æ›´æµç•…ã€ç”ŸåŠ¨ä¸”ç¬¦åˆä¸­æ–‡å†™ä½œä¹ æƒ¯ã€‚"
        return original_segment, modification_request

# ä¿ç•™åŸæœ‰çš„ai_generateå‡½æ•°ä»¥å…¼å®¹å…¶ä»–å¯èƒ½çš„è°ƒç”¨
def ai_generate(client: AIModelClient, task_type: str, segment: str, user_extra: str, selected_task: str = "") -> str:
    """ä½¿ç”¨AIç”ŸæˆåŠ©æ‰‹å›å¤ï¼ŒåŸºäºæ‹†åˆ†çš„åŸæ–‡ç”Ÿæˆå†…å®¹ï¼ˆå…¼å®¹å‡½æ•°ï¼‰"""
    if task_type == 'å†™ä½œ':
        return ai_generate_writing(client, segment, user_extra, selected_task)
    elif task_type == 'ç»­å†™':
        return ai_generate_continuation(client, segment, user_extra, selected_task)
    else:  # ä¿®æ”¹
        return ai_generate_modification(client, segment, user_extra, selected_task)

def ai_generate_user_content(client: AIModelClient, task_type: str, assistant_content: str, user_extra: str) -> str:
    """åŸºäºassistantå†…å®¹ç”Ÿæˆuserå†…å®¹ï¼ˆå…¼å®¹å‡½æ•°ï¼‰"""
    if task_type == 'å†™ä½œ':
        return ai_generate_writing_prompt(client, assistant_content, user_extra)
    elif task_type == 'ç»­å†™':
        return f"è¯·ç»­å†™ä»¥ä¸‹æ®µè½ï¼š\n\nã€{assistant_content[:200]}...ã€"
    else:  # ä¿®æ”¹
        original_text, modification_request = ai_generate_modification_prompt(client, assistant_content, assistant_content, user_extra)
        return f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–è¿™æ®µæ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{modification_request}\n\næ–‡æœ¬ï¼š\nã€{original_text}ã€"

def get_default_user_content(task_type: str, user_extra: str) -> str:
    """è·å–é»˜è®¤ç”¨æˆ·å†…å®¹"""
    if task_type == 'å†™ä½œ':
        return user_extra.strip() or "è¯·åˆ›ä½œä¸€æ®µå°è¯´å†…å®¹ã€‚"
    elif task_type == 'ç»­å†™':
        return "è¯·ç»­å†™ä»¥ä¸‹å†…å®¹ã€‚"
    else:  # ä¿®æ”¹
        return user_extra.strip() or "è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬å†…å®¹ã€‚"

def get_default_prompt(task_type: str) -> str:
    """è·å–é»˜è®¤æç¤ºè¯"""
    if task_type == 'å†™ä½œ':
        return 'è¯·æ ¹æ®å‚è€ƒæ–‡æœ¬å’Œåˆ›ä½œè¦æ±‚ï¼Œç”Ÿæˆä¸€æ®µé«˜è´¨é‡çš„å°è¯´å†…å®¹ã€‚ä¿æŒæ–‡é£ä¸€è‡´ï¼Œæƒ…èŠ‚åˆç†ï¼Œå­—æ•°æ§åˆ¶åœ¨300-500å­—ã€‚'
    elif task_type == 'ç»­å†™':
        return 'è¯·æ ¹æ®ä¸Šæ–‡å†…å®¹ï¼Œè‡ªç„¶åœ°ç»­å†™æ¥ä¸‹æ¥çš„æƒ…èŠ‚ã€‚ä¿æŒåŸæœ‰çš„å†™ä½œé£æ ¼ã€äººç‰©æ€§æ ¼å’Œæ•…äº‹èŠ‚å¥ã€‚ç»­å†™å†…å®¹åº”è¯¥åœ¨300-500å­—ä¹‹é—´ï¼Œæƒ…èŠ‚è¦æœ‰é€»è¾‘æ€§å’Œè¿è´¯æ€§ã€‚'
    else:  # ä¿®æ”¹
        return 'è¯·å¯¹åŸæ–‡è¿›è¡Œæ¶¦è‰²å’Œä¼˜åŒ–ï¼Œæå‡è¯­è¨€è¡¨è¾¾çš„æµç•…æ€§ã€å‡†ç¡®æ€§å’Œæ–‡å­¦æ€§ã€‚ä¿æŒåŸæ„ä¸å˜ï¼Œä½†è®©è¡¨è¾¾æ›´åŠ ç”ŸåŠ¨ã€è‡ªç„¶ã€‚'

# æ‰«æç›®å½• txt æ–‡ä»¶

def scan_dir_txts(dir_path: str) -> List[str]:
    p = Path(dir_path)
    if not p.exists():
        return []
    return [str(fp) for fp in p.rglob('*.txt') if fp.is_file()]

# ==================== æ¨¡å‹ç®¡ç†å‡½æ•° ====================

def load_model_config(config_name: str, base_url: str = "", api_key: str = "", 
                     model_name: str = "", timeout: int = 30) -> Tuple[str, str]:
    """åŠ è½½æ¨¡å‹é…ç½®"""
    global current_model_client
    
    try:
        if config_name == "è‡ªå®šä¹‰":
            if not (base_url and api_key and model_name):
                return "âŒ è‡ªå®šä¹‰é…ç½®éœ€è¦å¡«å†™å®Œæ•´çš„è¿æ¥ä¿¡æ¯", ""
            
            config = ModelConfig(
                name="è‡ªå®šä¹‰",
                base_url=base_url,
                api_key=api_key,
                model_name=model_name,
                timeout=timeout
            )
        else:
            # ä»é¢„è®¾æˆ–è‡ªå®šä¹‰é…ç½®ä¸­åŠ è½½
            all_configs = AIModelClient.get_all_configs()
            if config_name not in all_configs:
                return f"âŒ é…ç½® '{config_name}' ä¸å­˜åœ¨", ""
            
            config_dict = all_configs[config_name]
            if not config_dict.get('api_key'):
                return f"âŒ é…ç½® '{config_name}' ç¼ºå°‘ API Key", ""
            
            config = ModelConfig(
                name=config_dict['name'],
                base_url=config_dict['base_url'],
                api_key=config_dict['api_key'],
                model_name=config_dict['model_name'],
                timeout=config_dict.get('timeout', 30)
            )
        
        # åˆ›å»ºå®¢æˆ·ç«¯
        current_model_client = AIModelClient(config)
        
        # æµ‹è¯•è¿æ¥
        logger.info(f"æ­£åœ¨æµ‹è¯•æ¨¡å‹è¿æ¥: {config.name}")
        if current_model_client.test_connection():
            message = f"âœ… æ¨¡å‹ {config.name} åŠ è½½æˆåŠŸå¹¶è¿æ¥æ­£å¸¸"
            logger.info(message)
            return message, "è¿æ¥æˆåŠŸ"
        else:
            message = f"âš ï¸ æ¨¡å‹ {config.name} åŠ è½½æˆåŠŸä½†è¿æ¥æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®"
            logger.warning(message)
            return message, "è¿æ¥å¤±è´¥"
            
    except Exception as e:
        error_msg = f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}"
        logger.error(error_msg)
        return error_msg, "åŠ è½½å¤±è´¥"

def save_model_config(name: str, base_url: str, api_key: str, model_name: str, 
                     timeout: int) -> str:
    """ä¿å­˜æ¨¡å‹é…ç½®"""
    try:
        if not all([name, base_url, api_key, model_name]):
            return "âŒ æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å¡«å†™"
        
        config = {
            "name": name,
            "base_url": base_url,
            "api_key": api_key,
            "model_name": model_name,
            "timeout": timeout,
            "temperature": 0.7
        }
        
        AIModelClient.save_custom_config(config)
        return f"âœ… é…ç½® '{name}' ä¿å­˜æˆåŠŸ"
        
    except Exception as e:
        return f"âŒ ä¿å­˜å¤±è´¥: {str(e)}"

# ==================== ä»»åŠ¡ç®¡ç†å‡½æ•° ====================

def get_task_prompt_display(task_name: str) -> str:
    """è·å–ä»»åŠ¡æç¤ºè¯ç”¨äºæ˜¾ç¤º"""
    if not task_name:
        return ""
    return task_manager.get_task_prompt(task_name)

def add_custom_task(name: str, prompt: str) -> Tuple[str, gr.Dropdown]:
    """æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡"""
    if not name or not prompt:
        return "âŒ ä»»åŠ¡åç§°å’Œæç¤ºè¯ä¸èƒ½ä¸ºç©º", gr.Dropdown()
    
    if task_manager.add_custom_task(name, prompt):
        updated_choices = task_manager.get_task_names() + ["è‡ªå®šä¹‰"]
        return f"âœ… ä»»åŠ¡ '{name}' æ·»åŠ æˆåŠŸ", gr.Dropdown(choices=updated_choices)
    else:
        return "âŒ æ·»åŠ ä»»åŠ¡å¤±è´¥", gr.Dropdown()

def delete_custom_task(name: str) -> Tuple[str, gr.Dropdown]:
    """åˆ é™¤è‡ªå®šä¹‰ä»»åŠ¡"""
    if not name:
        return "âŒ è¯·é€‰æ‹©è¦åˆ é™¤çš„ä»»åŠ¡", gr.Dropdown()
    
    if name in task_manager.predefined_tasks:
        return "âŒ ä¸èƒ½åˆ é™¤é¢„è®¾ä»»åŠ¡", gr.Dropdown()
    
    if task_manager.delete_custom_task(name):
        updated_choices = task_manager.get_task_names() + ["è‡ªå®šä¹‰"]
        return f"âœ… ä»»åŠ¡ '{name}' åˆ é™¤æˆåŠŸ", gr.Dropdown(choices=updated_choices)
    else:
        return "âŒ åˆ é™¤ä»»åŠ¡å¤±è´¥", gr.Dropdown()

# ==================== æ ¸å¿ƒå¤„ç†å‡½æ•° ====================

def build_jsonl(files: List[str], min_len: int, max_len: int, mode: str, task_type: str,
                system_prompt: str, user_extra: str, selected_task: str = "", 
                progress=gr.Progress()) -> Tuple[str, str]:
    """æ„å»ºJSONLæ•°æ®é›†"""
    global current_model_client
    
    # ä¿®å¤filesä¸ºNoneçš„é”™è¯¯
    if files is None:
        return None, 'æœªé€‰æ‹©æœ‰æ•ˆTXTæ–‡ä»¶'
    
    all_files = [f for f in files if f and os.path.isfile(f)]
    if not all_files:
        return None, 'æœªé€‰æ‹©æœ‰æ•ˆTXTæ–‡ä»¶'

    # æ ¹æ®ä»»åŠ¡ç±»å‹å’Œæ¨¡å¼åˆ¤æ–­æ˜¯å¦éœ€è¦AIæ¨¡å‹
    needs_ai = False
    if mode == 'AIç”Ÿæˆ':
        needs_ai = True
    elif mode == 'ä½¿ç”¨åŸæ–‡' and task_type == 'å†™ä½œ':
        # å†™ä½œä»»åŠ¡åœ¨ä½¿ç”¨åŸæ–‡æ¨¡å¼ä¸‹ä¹Ÿéœ€è¦AIæ¥åæ¨åˆ›ä½œè¦æ±‚
        needs_ai = True
    elif mode == 'ä½¿ç”¨åŸæ–‡' and task_type == 'ä¿®æ”¹':
        # ä¿®æ”¹ä»»åŠ¡åœ¨ä½¿ç”¨åŸæ–‡æ¨¡å¼ä¸‹ä¹Ÿéœ€è¦AIæ¥ç”Ÿæˆä¿®æ”¹è¦æ±‚
        needs_ai = True
    
    if needs_ai and current_model_client is None:
        return None, 'å½“å‰ä»»åŠ¡éœ€è¦AIæ¨¡å‹æ”¯æŒï¼Œè¯·å…ˆåŠ è½½AIæ¨¡å‹'

    # åˆ›å»ºtempç›®å½•
    temp_dir = Path("temp")
    temp_dir.mkdir(exist_ok=True)

    dataset = []
    total_segments = 0
    
    # ç»Ÿè®¡æ€»ç‰‡æ®µæ•°
    for fp in all_files:
        txt = read_text(fp)
        segs = split_text(txt, min_len, max_len)
        total_segments += len(segs)
    
    processed_segments = 0
    
    for fp in all_files:
        txt = read_text(fp)
        segs = split_text(txt, min_len, max_len)
        
        for i, seg in enumerate(segs):
            processed_segments += 1
            progress_ratio = processed_segments / total_segments
            progress(progress_ratio, desc=f"å¤„ç† {os.path.basename(fp)} ({i+1}/{len(segs)})")
            
            # æ ¹æ®ä»»åŠ¡ç±»å‹ç”Ÿæˆä¸åŒæ ¼å¼çš„æ•°æ®
            if task_type == 'ç»­å†™':
                # ç»­å†™ä»»åŠ¡ï¼šä½¿ç”¨å½“å‰æ®µè½ä½œä¸ºä¸Šæ–‡ï¼Œä¸‹ä¸€æ®µè½ä½œä¸ºç»­å†™å†…å®¹
                # ç»­å†™ä»»åŠ¡ä¸éœ€è¦AIåæ¨ï¼Œæ ¼å¼ç›¸å¯¹å›ºå®š
                if i < len(segs) - 1:  # ç¡®ä¿æœ‰ä¸‹ä¸€æ®µ
                    current_seg = seg
                    next_seg = segs[i + 1]
                    
                    if mode == 'AIç”Ÿæˆ':
                        # AIç”Ÿæˆç»­å†™å†…å®¹
                        assistant_content = ai_generate_continuation(current_model_client, current_seg, user_extra, selected_task)
                        user_content = f"è¯·ç»­å†™ä»¥ä¸‹æ®µè½ï¼š\n\nã€{current_seg}ã€"
                    elif mode == 'ä½¿ç”¨åŸæ–‡':
                        # ä½¿ç”¨ä¸‹ä¸€æ®µä½œä¸ºç»­å†™å†…å®¹ï¼Œä¸éœ€è¦AI
                        assistant_content = next_seg
                        user_content = f"è¯·ç»­å†™ä»¥ä¸‹æ®µè½ï¼š\n\nã€{current_seg}ã€"
                    else:  # ç©ºç™½
                        assistant_content = ''
                        user_content = f"è¯·ç»­å†™ä»¥ä¸‹æ®µè½ï¼š\n\nã€{current_seg}ã€"
                    
                    msgs = [
                        {"role": "system", "content": system_prompt.strip() or "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æä¾›çš„å°è¯´ä¸Šæ–‡ï¼Œè‡ªç„¶åœ°ç»­å†™æ¥ä¸‹æ¥çš„æƒ…èŠ‚ã€‚"},
                        {"role": "user", "content": user_content},
                        {"role": "assistant", "content": assistant_content}
                    ]
                    dataset.append({"messages": msgs})
                    
            elif task_type == 'å†™ä½œ':
                 # å†™ä½œä»»åŠ¡ï¼šéœ€è¦AIåæ¨åˆ›ä½œè¦æ±‚ï¼ˆé™¤äº†ç©ºç™½æ¨¡å¼ï¼‰
                 if mode == 'AIç”Ÿæˆ':
                     # å…ˆç”Ÿæˆåˆ›ä½œå†…å®¹ï¼Œç„¶ååæ¨åˆ›ä½œè¦æ±‚ï¼ˆéœ€è¦AIï¼‰
                     assistant_content = ai_generate_writing(current_model_client, seg, user_extra, selected_task)
                     user_content = ai_generate_writing_prompt(current_model_client, assistant_content, user_extra)
                 elif mode == 'ä½¿ç”¨åŸæ–‡':
                     # ä½¿ç”¨åŸæ–‡ä½œä¸ºåˆ›ä½œå†…å®¹ï¼Œéœ€è¦AIåæ¨åˆ›ä½œè¦æ±‚
                     assistant_content = seg
                     if current_model_client:
                         user_content = ai_generate_writing_prompt(current_model_client, assistant_content, user_extra)
                     else:
                         # å¦‚æœæ²¡æœ‰AIæ¨¡å‹ï¼Œä½¿ç”¨ç®€å•çš„é»˜è®¤æç¤º
                         user_content = user_extra.strip() or "è¯·åˆ›ä½œä¸€æ®µå°è¯´å†…å®¹ã€‚"
                 else:  # ç©ºç™½æ¨¡å¼ï¼Œä¸éœ€è¦AI
                     assistant_content = ''
                     user_content = user_extra.strip() or "è¯·åˆ›ä½œä¸€æ®µå°è¯´å†…å®¹ã€‚"
                 
                 msgs = [
                     {"role": "system", "content": system_prompt.strip() or "ä½ æ˜¯ä¸€åä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·çš„æŒ‡ä»¤ç”Ÿæˆç”ŸåŠ¨ã€æœ‰è¶£çš„æ•…äº‹ç‰‡æ®µã€‚"},
                     {"role": "user", "content": user_content},
                     {"role": "assistant", "content": assistant_content}
                 ]
                 dataset.append({"messages": msgs})
                
            else:  # ä¿®æ”¹ä»»åŠ¡
                 # ä¿®æ”¹ä»»åŠ¡ï¼šéœ€è¦AIç”Ÿæˆä¿®æ”¹è¦æ±‚ï¼ˆé™¤äº†ç©ºç™½æ¨¡å¼ï¼‰
                 if mode == 'AIç”Ÿæˆ':
                     # ç”Ÿæˆä¿®æ”¹åçš„å†…å®¹ï¼Œç„¶ååæ¨ä¿®æ”¹è¦æ±‚ï¼ˆéœ€è¦AIï¼‰
                     assistant_content = ai_generate_modification(current_model_client, seg, user_extra, selected_task)
                     original_text, modification_request = ai_generate_modification_prompt(current_model_client, seg, assistant_content, user_extra)
                     user_content = f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–è¿™æ®µæ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{modification_request}\n\næ–‡æœ¬ï¼š\nã€{original_text}ã€"
                 elif mode == 'ä½¿ç”¨åŸæ–‡':
                     # ä½¿ç”¨åŸæ–‡ä½œä¸ºä¿®æ”¹åçš„å†…å®¹ï¼Œéœ€è¦AIç”Ÿæˆä¿®æ”¹è¦æ±‚
                     assistant_content = seg
                     if current_model_client:
                         original_text, modification_request = ai_generate_modification_prompt(current_model_client, seg, seg, user_extra)
                         user_content = f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–è¿™æ®µæ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{modification_request}\n\næ–‡æœ¬ï¼š\nã€{original_text}ã€"
                     else:
                         # å¦‚æœæ²¡æœ‰AIæ¨¡å‹ï¼Œä½¿ç”¨ç®€å•çš„é»˜è®¤ä¿®æ”¹è¦æ±‚
                         modification_request = user_extra.strip() or "è¯·ä¼˜åŒ–æ–‡ç¬”ï¼Œä½¿å…¶æ›´æµç•…ã€ç”ŸåŠ¨ä¸”ç¬¦åˆä¸­æ–‡å†™ä½œä¹ æƒ¯ã€‚"
                         user_content = f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–è¿™æ®µæ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{modification_request}\n\næ–‡æœ¬ï¼š\nã€{seg}ã€"
                 else:  # ç©ºç™½æ¨¡å¼ï¼Œä¸éœ€è¦AI
                     assistant_content = ''
                     modification_request = user_extra.strip() or "è¯·ä¼˜åŒ–æ–‡ç¬”ï¼Œä½¿å…¶æ›´æµç•…ã€ç”ŸåŠ¨ä¸”ç¬¦åˆä¸­æ–‡å†™ä½œä¹ æƒ¯ã€‚"
                     user_content = f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚ä¼˜åŒ–è¿™æ®µæ–‡æœ¬ï¼š\n\nè¦æ±‚ï¼š{modification_request}\n\næ–‡æœ¬ï¼š\nã€{seg}ã€"
                 
                 msgs = [
                     {"role": "system", "content": system_prompt.strip() or "ä½ æ˜¯ä¸€åä¸“ä¸šçš„ç¼–è¾‘åŠ©æ‰‹ï¼Œæ“…é•¿æ ¹æ®ç”¨æˆ·çš„è¦æ±‚å¯¹æ–‡å­—è¿›è¡Œæ¶¦è‰²ã€ä¿®æ”¹å’Œä¼˜åŒ–ã€‚"},
                     {"role": "user", "content": user_content},
                     {"role": "assistant", "content": assistant_content}
                 ]
                 dataset.append({"messages": msgs})

    # ä¿å­˜æ–‡ä»¶
    out_dir = Path(__file__).parent / 'è¾“å‡ºæ•°æ®é›†'
    out_dir.mkdir(parents=True, exist_ok=True)
    ts = time.strftime('%Y%m%d_%H%M%S')
    task_suffix = selected_task if selected_task and selected_task != "è‡ªå®šä¹‰" else task_type
    out_path = out_dir / f'dataset_{task_suffix}_{mode}_{ts}.jsonl'
    
    with open(out_path, 'w', encoding='utf-8') as f:
        for item in dataset:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    return str(out_path), f'å·²ç”Ÿæˆ {len(dataset)} æ¡æ ·æœ¬ï¼Œä¿å­˜åˆ°ï¼š{out_path}'

# ==================== Gradio UI ====================

def scan_directory(dir_path: str) -> List[str]:
    """æ‰«æç›®å½•ä¸­çš„txtæ–‡ä»¶"""
    if not dir_path or not os.path.exists(dir_path):
        return []
    return scan_dir_txts(dir_path)

def create_ui():
    with gr.Blocks(title='å°è¯´æ•°æ®é›†æ„å»ºå·¥å…·', theme=gr.themes.Ocean()) as demo:
        gr.Markdown('# ğŸ“š å°è¯´æ•°æ®é›†æ„å»ºå·¥å…·\n\nå°†å°è¯´æ–‡æœ¬è½¬æ¢ä¸º JSONL messages æ ¼å¼ï¼Œç”¨äºå¤§æ¨¡å‹å¾®è°ƒ')
        
        with gr.Tabs():
            # ä¸»è¦åŠŸèƒ½æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ“– æ•°æ®é›†æ„å»º"):
                with gr.Row():
                    with gr.Column(scale=2):
                        gr.Markdown('### ğŸ“ è¾“å…¥æ–‡ä»¶')
                        files = gr.File(label='ä¸Šä¼ TXTæ–‡ä»¶', file_count='multiple', file_types=['.txt'])
                        dir_path = gr.Textbox(label='æˆ–æŒ‡å®šç›®å½•è·¯å¾„', placeholder='ä¾‹ï¼šD:/novels')
                        scan_btn = gr.Button('ğŸ“‚ æ‰«æç›®å½•', variant='secondary')
                        file_list = gr.Textbox(label='å¾…å¤„ç†æ–‡ä»¶åˆ—è¡¨', lines=3, interactive=False)
                        
                        gr.Markdown('### âš™ï¸ åˆ†æ®µè®¾ç½®')
                        with gr.Row():
                            min_len = gr.Number(label='æœ€å°é•¿åº¦', value=200, minimum=50)
                            max_len = gr.Number(label='æœ€å¤§é•¿åº¦', value=800, minimum=100)
                        
                        gr.Markdown('### ğŸ¯ å†…å®¹ç”Ÿæˆ')
                        mode = gr.Radio(['AIç”Ÿæˆ', 'ä½¿ç”¨åŸæ–‡', 'ç©ºç™½'], label='åŠ©æ‰‹å†…å®¹æ¥æº', value='AIç”Ÿæˆ')
                        task_type = gr.Radio(['å†™ä½œ', 'ç»­å†™', 'ä¿®æ”¹'], label='ä»»åŠ¡ç±»å‹', value='ç»­å†™')
                        
                        # ä»»åŠ¡é€‰æ‹©
                        with gr.Row():
                            task_choices = task_manager.get_task_names() + ["è‡ªå®šä¹‰"]
                            selected_task = gr.Dropdown(
                                choices=task_choices,
                                label='é¢„è®¾ä»»åŠ¡æ¨¡æ¿',
                                value='å°è¯´ç»­å†™' if 'å°è¯´ç»­å†™' in task_choices else task_choices[0] if task_choices else "è‡ªå®šä¹‰"
                            )
                        
                        task_prompt_display = gr.Textbox(
                            label='å½“å‰ä»»åŠ¡æç¤ºè¯',
                            lines=3,
                            interactive=False,
                            value=task_manager.get_task_prompt('å°è¯´ç»­å†™')
                        )
                        
                        system_prompt = gr.Textbox(
                            label='System æç¤ºè¯',
                            value='ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å°è¯´åˆ›ä½œåŠ©æ‰‹ï¼Œæ“…é•¿å„ç§æ–‡å­¦ä½“è£çš„å†™ä½œã€‚',
                            lines=2
                        )
                        user_extra = gr.Textbox(
                            label='é¢å¤–è¦æ±‚ï¼ˆå†™ä½œä¸»é¢˜/ä¿®æ”¹éœ€æ±‚ç­‰ï¼‰',
                            placeholder='ä¾‹ï¼šç§‘å¹»é¢˜æï¼Œæ³¨é‡äººç‰©å¿ƒç†æå†™',
                            lines=2
                        )
                        
                    with gr.Column(scale=1):
                        gr.Markdown('### ğŸ¤– AIæ¨¡å‹è®¾ç½®')
                        
                        # æ¨¡å‹é…ç½®é€‰æ‹©
                        all_configs = AIModelClient.get_all_configs()
                        config_choices = list(all_configs.keys()) + ["è‡ªå®šä¹‰"]
                        selected_config = gr.Dropdown(
                            choices=config_choices,
                            label='é€‰æ‹©æ¨¡å‹é…ç½®',
                            value=config_choices[0] if config_choices else "è‡ªå®šä¹‰"
                        )
                        
                        # æ¨¡å‹è¿æ¥å‚æ•°
                        base_url = gr.Textbox(label='Base URL', value='https://api.deepseek.com/v1')
                        api_key = gr.Textbox(label='API Key', type='password')
                        model_name = gr.Textbox(label='Model Name', value='deepseek-chat')
                        timeout = gr.Number(label='è¶…æ—¶æ—¶é—´(ç§’)', value=30, minimum=10)
                        
                        # æ¨¡å‹æ“ä½œæŒ‰é’®
                        with gr.Row():
                            load_model_btn = gr.Button('ğŸ”— åŠ è½½æ¨¡å‹', variant='secondary')
                            test_model_btn = gr.Button('ğŸ§ª æµ‹è¯•è¿æ¥', variant='secondary')
                        
                        model_status = gr.Textbox(label='æ¨¡å‹çŠ¶æ€', interactive=False, lines=2)
                        
                        gr.Markdown('### ğŸš€ æ‰§è¡Œ')
                        build_btn = gr.Button('ğŸ”¨ å¼€å§‹æ„å»º', variant='primary', size='lg')
                        
                        gr.Markdown('### ğŸ“Š è¾“å‡º')
                        output_file = gr.File(label='ç”Ÿæˆçš„JSONLæ–‡ä»¶', interactive=False)
                        logs = gr.Textbox(label='å¤„ç†æ—¥å¿—', lines=6, interactive=False)
            
            # æ¨¡å‹ç®¡ç†æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ”§ æ¨¡å‹ç®¡ç†"):
                gr.Markdown('### ğŸ’¾ ä¿å­˜æ–°çš„æ¨¡å‹é…ç½®')
                with gr.Row():
                    with gr.Column():
                        new_config_name = gr.Textbox(label='é…ç½®åç§°', placeholder='ä¾‹ï¼šæˆ‘çš„DeepSeek')
                        new_base_url = gr.Textbox(label='Base URL', placeholder='https://api.deepseek.com/v1')
                        new_api_key = gr.Textbox(label='API Key', type='password')
                        new_model_name = gr.Textbox(label='Model Name', placeholder='deepseek-chat')
                        new_timeout = gr.Number(label='è¶…æ—¶æ—¶é—´(ç§’)', value=30, minimum=10)
                        
                        save_config_btn = gr.Button('ğŸ’¾ ä¿å­˜é…ç½®', variant='primary')
                        save_config_status = gr.Textbox(label='ä¿å­˜çŠ¶æ€', interactive=False)
                
                gr.Markdown('### ğŸ“‹ ç°æœ‰é…ç½®åˆ—è¡¨')
                config_list = gr.Textbox(
                    label='å·²ä¿å­˜çš„é…ç½®',
                    value='\n'.join([f"â€¢ {name}: {config.get('base_url', 'N/A')}" for name, config in all_configs.items()]),
                    lines=8,
                    interactive=False
                )
            
            # ä»»åŠ¡ç®¡ç†æ ‡ç­¾é¡µ
            with gr.TabItem("ğŸ“ ä»»åŠ¡ç®¡ç†"):
                gr.Markdown('### â• æ·»åŠ è‡ªå®šä¹‰ä»»åŠ¡')
                with gr.Row():
                    with gr.Column():
                        new_task_name = gr.Textbox(label='ä»»åŠ¡åç§°', placeholder='ä¾‹ï¼šè§’è‰²å¯¹è¯ç”Ÿæˆ')
                        new_task_prompt = gr.Textbox(
                            label='ä»»åŠ¡æç¤ºè¯',
                            placeholder='è¯·è¯¦ç»†æè¿°ä»»åŠ¡è¦æ±‚...',
                            lines=4
                        )
                        
                        with gr.Row():
                            add_task_btn = gr.Button('â• æ·»åŠ ä»»åŠ¡', variant='primary')
                            delete_task_btn = gr.Button('ğŸ—‘ï¸ åˆ é™¤ä»»åŠ¡', variant='secondary')
                        
                        task_management_status = gr.Textbox(label='æ“ä½œçŠ¶æ€', interactive=False)
                
                gr.Markdown('### ğŸ“‹ ç°æœ‰ä»»åŠ¡åˆ—è¡¨')
                task_list_display = gr.Textbox(
                    label='æ‰€æœ‰ä»»åŠ¡',
                    value='\n'.join([f"â€¢ {name}: {prompt[:50]}..." for name, prompt in task_manager.get_all_tasks().items()]),
                    lines=10,
                    interactive=False
                )
                
                # åˆ é™¤ä»»åŠ¡çš„ä¸‹æ‹‰é€‰æ‹©
                delete_task_dropdown = gr.Dropdown(
                    choices=[name for name in task_manager.get_task_names() if name not in task_manager.predefined_tasks],
                    label='é€‰æ‹©è¦åˆ é™¤çš„è‡ªå®šä¹‰ä»»åŠ¡',
                    value=None
                )
        
        # ==================== äº‹ä»¶ç»‘å®š ====================
        
        # æ–‡ä»¶å’Œç›®å½•å¤„ç†
        scan_btn.click(
            fn=lambda path: '\n'.join(scan_directory(path)) if path else 'è¯·è¾“å…¥ç›®å½•è·¯å¾„',
            inputs=[dir_path],
            outputs=[file_list]
        )
        
        files.change(
            fn=lambda fs: '\n'.join([f.name for f in fs]) if fs else '',
            inputs=[files],
            outputs=[file_list]
        )
        
        # ä»»åŠ¡é€‰æ‹©å˜åŒ–æ—¶æ›´æ–°æç¤ºè¯æ˜¾ç¤º
        selected_task.change(
            fn=get_task_prompt_display,
            inputs=[selected_task],
            outputs=[task_prompt_display]
        )
        
        # æ¨¡å‹é…ç½®é€‰æ‹©å˜åŒ–æ—¶æ›´æ–°å‚æ•°
        def update_model_params(config_name):
            if config_name == "è‡ªå®šä¹‰":
                return "", "", "", 30
            
            all_configs = AIModelClient.get_all_configs()
            if config_name in all_configs:
                config = all_configs[config_name]
                return (
                    config.get('base_url', ''),
                    '',  # ä¸æ˜¾ç¤ºä¿å­˜çš„API Key
                    config.get('model_name', ''),
                    config.get('timeout', 30)
                )
            return "", "", "", 30
        
        selected_config.change(
            fn=update_model_params,
            inputs=[selected_config],
            outputs=[base_url, api_key, model_name, timeout]
        )
        
        # æ¨¡å‹æ“ä½œ
        load_model_btn.click(
            fn=load_model_config,
            inputs=[selected_config, base_url, api_key, model_name, timeout],
            outputs=[model_status, gr.Textbox(visible=False)]  # ç¬¬äºŒä¸ªè¾“å‡ºç”¨äºå†…éƒ¨çŠ¶æ€
        )
        
        # ä¿å­˜æ¨¡å‹é…ç½®
        save_config_btn.click(
            fn=save_model_config,
            inputs=[new_config_name, new_base_url, new_api_key, new_model_name, new_timeout],
            outputs=[save_config_status]
        )
        
        # ä»»åŠ¡ç®¡ç†
        add_task_btn.click(
            fn=add_custom_task,
            inputs=[new_task_name, new_task_prompt],
            outputs=[task_management_status, selected_task]
        )
        
        delete_task_btn.click(
            fn=delete_custom_task,
            inputs=[delete_task_dropdown],
            outputs=[task_management_status, selected_task]
        )
        
        # ä¸»è¦æ„å»ºåŠŸèƒ½
        build_btn.click(
            fn=build_jsonl,
            inputs=[files, min_len, max_len, mode, task_type, system_prompt, user_extra, selected_task],
            outputs=[output_file, logs]
        )
    
    return demo

def ui_app():
    return create_ui()

if __name__ == '__main__':
    ui_app().launch()